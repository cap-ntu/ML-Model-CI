{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation, Converting and Registering Image Classification Model by ModelCI\n",
    "\n",
    "This is a getting started tutorial for those who are new to ML-ModelCI, by the end of this tutorial, you will be able to: \n",
    "\n",
    "- Setting up python environment required by ML-ModelCI.\n",
    "- Start and stop ModelCI service.\n",
    "- Master basic usages of ML-ModelCI, such as model loading, registering,retrieving and converting.\n",
    "- Have a basic understanding of machine learning model lifecycle.\n",
    "\n",
    "## 1. Installation\n",
    "\n",
    "Here are some prequisities before installation\n",
    "\n",
    "- Python version: 3.7\n",
    "- Docker service installed and started\n",
    "- Manually install [TensorRT](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html) if your linux distribution is not Ubuntu\n",
    "\n",
    "Firstly, we should install dependencies specified in `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can install the ModelCI python package based on <https://github.com/cap-ntu/ML-Model-CI#using-pip>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/cap-ntu/ML-Model-CI.git@master --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the ModelCI Service\n",
    "\n",
    "Firstly, we should set some environmemnt variables, especially mongodb related variables, just make sure the port you specified is not occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MONGO_HOST=localhost\n",
      "env: MONGO_PORT=27017\n",
      "env: MONGO_USERNAME=modelci\n",
      "env: MONGO_PASSWORD=modelci@2020\n",
      "env: MONGO_DB=modelci\n",
      "env: MONGO_AUTH_SOURCE=modelci\n",
      "env: BACKEND_CORS_ORIGINS=\"http://localhost,http://localhost:3000,http://localhost:8080,https://localhost:3000,https://localhost:8080\"\n",
      "env: PROJECT_NAME=modelci\n",
      "env: SECRET_KEY=2a6c03b9ca06cd8fc3cf506f0ba924cb735f15918d54758426fd7282366a5e19\n"
     ]
    }
   ],
   "source": [
    "# set environment variables \n",
    "%env MONGO_HOST=localhost\n",
    "%env MONGO_PORT=27017\n",
    "%env MONGO_USERNAME=modelci\n",
    "%env MONGO_PASSWORD=modelci@2020\n",
    "%env MONGO_DB=modelci\n",
    "%env MONGO_AUTH_SOURCE=modelci\n",
    "%env BACKEND_CORS_ORIGINS=\"http://localhost,http://localhost:3000,http://localhost:8080,https://localhost:3000,https://localhost:8080\"\n",
    "%env PROJECT_NAME=modelci\n",
    "%env SECRET_KEY=2a6c03b9ca06cd8fc3cf506f0ba924cb735f15918d54758426fd7282366a5e19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start the modelci service by following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-24 10:13:59,575 - ml-modelci Docker Container Manager - INFO - Container name=mongo-80889 stared\n",
      "2020-12-24 10:14:00,946 - ml-modelci Docker Container Manager - INFO - Container name=cadvisor-59832 started.\n",
      "2020-12-24 10:14:03,158 - ml-modelci Docker Container Manager - INFO - Container name=dcgm-exporter-65806 started.\n",
      "2020-12-24 10:14:04,355 - ml-modelci Docker Container Manager - INFO - gpu-metrics-exporter-93245 stared\n",
      "2020-12-24 10:14:04,486 - modelci backend - INFO - Uvicorn server listening on 8000\n"
     ]
    }
   ],
   "source": [
    "!modelci start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Register ResNet50 Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we load pre-trained resnet50 model from torchvision, you can refer to <https://pytorch.org/docs/stable/torchvision/models.html> for more examples of pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load resnet50 model from torchvision\n",
    "from torchvision import models\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we register this model into ModelHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.manager import register_model\n",
    "from modelci.types.bo import Framework, IOShape, ModelVersion, Engine, Metric, Task\n",
    "from modelci.types.trtis_objects import ModelInputFormat\n",
    "# set model input and output formats\n",
    "inputs = [IOShape([-1, 3, 224, 224], dtype=float, name='INPUT__0', format=ModelInputFormat.FORMAT_NCHW)]\n",
    "outputs = [IOShape([-1, 1000], dtype=float, name='probs')]\n",
    "# register the model\n",
    "register_model(\n",
    "    model,\n",
    "    dataset='imagenet',\n",
    "    metric={Metric.ACC: 0.76},\n",
    "    task=Task.IMAGE_CLASSIFICATION,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    architecture='ResNet50',\n",
    "    framework=Framework.PYTORCH,\n",
    "    version=ModelVersion('2')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve Models\n",
    "By default, Converter will automatically convert registered models into optimized formats,PyTorch model can be converted to TorchScipt and ONNX formats, so we can retrieve two models from ModelHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for model\n",
    "from modelci.hub.manager import retrieve_model\n",
    "retrieved_models = retrieve_model(\n",
    "        architecture_name = 'ResNet50',\n",
    "        framework = Framework.PYTORCH,\n",
    "        version=ModelVersion('2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<modelci.types.bo.model_bo.ModelBO at 0x7f40f03ebfd0>,\n",
       " <modelci.types.bo.model_bo.ModelBO at 0x7f40f0392b10>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare detatiled information of these two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5fe3f999c5b5a219d9c7f3f5',\n",
       " 'name': 'ResNet50',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.TORCHSCRIPT: 2>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7f40f03eb050>,\n",
       " 'dataset': 'imagenet',\n",
       " 'metric': {<Metric.ACC: 0>: 0.76},\n",
       " 'task': <Task.IMAGE_CLASSIFICATION: 0>,\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7f40f03eb410>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7f40f03eb910>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7f40f03eb710>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.RUNNING: 2>,\n",
       " 'creator': 'sherry',\n",
       " 'create_time': datetime.datetime(2020, 12, 24, 10, 14, 42, 555000)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_models[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5fe3f99ac5b5a219d9c7f580',\n",
       " 'name': 'ResNet50',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.ONNX: 3>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7f40f03eb350>,\n",
       " 'dataset': 'imagenet',\n",
       " 'metric': {<Metric.ACC: 0>: 0.76},\n",
       " 'task': <Task.IMAGE_CLASSIFICATION: 0>,\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7f40f03ebd10>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7f40f03eb550>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7f40f0392990>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.UNKNOWN: 0>,\n",
       " 'creator': 'sherry',\n",
       " 'create_time': datetime.datetime(2020, 12, 24, 10, 14, 42, 555000)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_models[1].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert Models\n",
    "We can convert models mannually. \n",
    "\n",
    "You can refer to <https://github.com/cap-ntu/ML-Model-CI/blob/master/docs/tutorial/convert.md> for more details.\n",
    "\n",
    "In the following example, we will convert ONNX model into TensorRT format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.converter import TRTConverter\n",
    "from modelci.hub.utils import generate_path\n",
    "from modelci.types.bo import IOShape\n",
    "\n",
    "# set model input and output formats\n",
    "inputs = [IOShape([-1, 3, 224, 224], dtype=float, name='INPUT__0', format=ModelInputFormat.FORMAT_NCHW)]\n",
    "outputs = [IOShape([-1, 1000], dtype=float, name='probs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sherry/.modelci/ResNet50/pytorch-onnx/image_classification/2.onnx')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ONNX model saved path\n",
    "onnx_path = retrieved_models[1].saved_path\n",
    "onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sherry/.modelci/ResNet50/pytorch-trt/image_classification/2')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set TensorRT format model save path\n",
    "save_path = generate_path(\n",
    "    model_name='ResNet50',\n",
    "    framework=Framework.PYTORCH,\n",
    "    task=Task.IMAGE_CLASSIFICATION,\n",
    "    engine=Engine.TRT,\n",
    "    version=2\n",
    ")\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONNX file from path /home/sherry/.modelci/ResNet50/pytorch-onnx/image_classification/2.onnx...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelci.hub.converter import PyTorchConverter\n",
    "TRTConverter.from_onnx(onnx_path, save_path, inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Stop the ModelCI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-24 10:18:42,950 - ml-modelci Docker Container Manager - INFO - Container name=gpu-metrics-exporter-93245 stopped.\n",
      "2020-12-24 10:18:44,102 - ml-modelci Docker Container Manager - INFO - Container name=dcgm-exporter-65806 stopped.\n",
      "2020-12-24 10:18:44,811 - ml-modelci Docker Container Manager - INFO - Container name=cadvisor-59832 stopped.\n",
      "2020-12-24 10:18:45,810 - ml-modelci Docker Container Manager - INFO - Container name=mongo-80889 stopped.\n",
      "2020-12-24 10:18:45,975 - modelci backend - INFO - The Uvicorn server with pid=10294 stopped.\n"
     ]
    }
   ],
   "source": [
    "!modelci stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can remove all the stoppped docker containers by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba1b7a33bf6e\n",
      "bc86a94e9aa0\n",
      "9a0c5774285f\n",
      "e561946d0205\n"
     ]
    }
   ],
   "source": [
    "!docker rm $(docker ps -a -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "```raw\n",
    "Copyright 2020 Nanyang Technological University, Singapore\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
