# Convert a Model to Optimized Formats for Production Purpose

The module focuses on automatically converting research models to serialized and optimized models from Python code.


We currently support 2 research frameworks:

-   TensorFlow
-   PyTorch

And MLModelCI supports the following conversions:

-   PyTorch -> TorchScript
-   PyTorch -> ONNX
-   Tensorflow -> Tensorflow-Serving format (TensorFlow-SavedModel)
-   Tensorflow -> TensorRT format
-   ONNX -> TensorRT format

Upon receiving your model registration, MLModelCI will help you to convert your model to as many as possible optimized formats. You can also use the following APIs to convert models manually.


These APIs will save the converted model in the given `saved_path` and return success or failure status of the conversion. We restrict to use the standard `saved_path` generated by `modelci.hub.utils.generate_path(...)` or path according to the rules (See [Tricks with Model Saved Path](./register.md#tricks-with-model-saved-path)). This path format can make your life easier.

### 1. TorchScript Conversion

```python
from modelci.hub.converter import TorchScriptConverter

torch_module = ...
saved_path = ...

TorchScriptConverter.from_torch_module(torch_module, saved_path)
```

### 2. TensorFlow Serving Conversion

```python
from modelci.hub.converter import TFSConverter

tf_module = ...
saved_path = ...

TFSConverter.from_tf_model(tf_module, saved_path)
```

### 3. ONNX Conversion

```python
from modelci.hub.converter import ONNXConverter

torch_module = ...
saved_path = ...
input_shape = ...
batch_size = ...

ONNXConverter.from_torch_module(torch_module, saved_path, input_shape, batch_size)
```

### 4. TRT Conversion

Different from the above converters, TRT accepts both tfsavedmodel and onnx formats for further optimization. In practice, if you use this pipeline: PyTorch -> onnx -> trt, you can get the best performance. However, in most cases, PyTorch model can not be further converted.

#### From TF Savedmodel to TF-TRT

```python
from modelci.hub.converter import TRTConverter
from modelci.persistence.bo import IOShape

tf_path = ...
trt_path = ...
inputs = [IOShape([...], dtype=..., format=...), ...]
outputs = [IOShape([...], dtype=..., format=...), ...]

TRTConverter.from_saved_model(tf_path, trt_path, inputs=inputs, outputs=outputs)
```

#### From ONNX to TRT

```python
from modelci.hub.converter import TRTConverter
from modelci.persistence.bo import IOShape

onnx_path = ...
save_path = ...
inputs = [IOShape([...], dtype=...), ...]
outputs = [IOShape([...], dtype=...), ...]

TRTConverter.from_onnx(onnx_path, save_path, inputs=inputs, outputs=outputs)
```
